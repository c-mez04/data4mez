{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "This Notebook will run through sevral models and model optimizing techniques. \n",
    "The dataset is the car evaluation dataset containing condition information on used car. This is a simple dataset just to demostrate how to evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing libraries for use later\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc\n",
       "3  vhigh  vhigh     2       2      med    low         unacc\n",
       "4  vhigh  vhigh     2       2      med    med         unacc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REading in the dataset\n",
    "data = pd.read_csv('assets/datasets/car.csv')\n",
    "# Let's see what the data looks like\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh' 'high' 'med' 'low']\n",
      "['vhigh' 'high' 'med' 'low']\n",
      "['small' 'med' 'big']\n",
      "['low' 'med' 'high']\n",
      "['unacc' 'acc' 'vgood' 'good']\n",
      "['2' '4' 'more']\n",
      "['2' '3' '4' '5more']\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the values in each columns\n",
    "print data.buying.unique()\n",
    "print data.maint.unique()\n",
    "print data.lug_boot.unique()\n",
    "print data.safety.unique()\n",
    "print data.acceptability.unique()\n",
    "print data.persons.unique()\n",
    "print data.doors.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's encode our values \n",
    "data['buying']= data.buying.factorize()[0]\n",
    "data['maint']= data.maint.factorize()[0]\n",
    "data['lug_boot']= data.lug_boot.factorize()[0]\n",
    "data['safety']= data.safety.factorize()[0]\n",
    "data['acceptability']= data.acceptability.factorize()[0]\n",
    "data['persons']= data.persons.factorize()[0]\n",
    "data['doors']= data.doors.factorize()[0]\n",
    "data.buying.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating x and y for modeling\n",
    "X = data.drop('buying', axis=1)\n",
    "y = data['buying']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "We are going to run several classification models and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carltonmezetin/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing metrics to score models on\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Accuracy score measures how many predictions our model correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=99, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model (model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print str((float(score) * 100)) + str('%')\n",
    "# Creating Dictionary of model scores for easy comparison\n",
    "model_score={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Models to use\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing Gridsearch to better tune models by finding best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.7360308285%\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "model = KNN(n_neighbors=14)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The score was bad using GridSearch we can find the best 'n' to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 97}\n",
      "0.288773148148\n"
     ]
    }
   ],
   "source": [
    "x = range(2,100)\n",
    "# Creating the dictionary of parameters to check\n",
    "params={'n_neighbors': x}\n",
    "knngrid = GridSearchCV(KNN(),\n",
    "                      params, n_jobs=-1,\n",
    "                      cv=KFold(len(y), n_folds=5, shuffle=True))\n",
    "knngrid.fit(X,y)\n",
    "\n",
    "print knngrid.best_params_\n",
    "print knngrid.best_score_\n",
    "\n",
    "# Our score got better with an 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.4431599229%\n"
     ]
    }
   ],
   "source": [
    "# Lets see if bagging our aggregating KNN\n",
    "bagknn = BaggingClassifier(KNN(n_neighbors=77))\n",
    "evaluate_model(bagknn)\n",
    "# It did get better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So gridsearching helped us before lets see if grid searching\n",
    "# our bagging classifier gets a better score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 1.0, 'max_samples': 0.7, 'n_estimators': 20, 'bootstrap_features': False}\n",
      "0.286458333333\n"
     ]
    }
   ],
   "source": [
    "gsbagknn.fit(X,y)\n",
    "print gsbagknn.best_params_\n",
    "print gsbagknn.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So our best KNN score was that our bagged KNN of 30.% So lets try another model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.901734104%\n"
     ]
    }
   ],
   "source": [
    "# Again we'll start with a basic Logistic Regression\n",
    "evaluate_model(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 100.0}\n",
      "0.313657407407\n"
     ]
    }
   ],
   "source": [
    "# This is our Grid Searched Logistic Regression\n",
    "lrparams ={'penalty':['l1', 'l2'],\n",
    "           'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "gslr = GridSearchCV(LogisticRegression(), \n",
    "                    lrparams, n_jobs=-1,\n",
    "                        cv=KFold(len(y), n_folds=3, shuffle=True))\n",
    "gslr.fit(X,y)\n",
    "\n",
    "print gslr.best_params_\n",
    "print gslr.best_score_\n",
    "# Score did get better now we know what parameters will get us a better score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 1.0, 'max_samples': 0.7, 'n_estimators': 10, 'bootstrap_features': False}\n",
      "0.317708333333\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with bagging, to see if this helps\n",
    " \n",
    "lrbag = BaggingClassifier(LogisticRegression())\n",
    "gsbaglr = GridSearchCV(lrbag, bagparams,\n",
    "                      n_jobs=5,\n",
    "                        cv=KFold(len(y), n_folds=5, shuffle=True))\n",
    "gsbaglr.fit(X,y)\n",
    "\n",
    "print gsbaglr.best_params_\n",
    "print gsbaglr.best_score_\n",
    "\n",
    "# Okay our score got slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For our Logistic Regression bagging gave us the highest score yet at 31.7%, only slightly better our bagged KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.3969171484%\n"
     ]
    }
   ],
   "source": [
    "#Let's see if SVM performs better\n",
    "svm = SVC()\n",
    "evaluate_model(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 1.0, 'gamma': 'auto'}\n",
      "0.332175925926\n"
     ]
    }
   ],
   "source": [
    "# Grid Search parametes for our Support Vector Machine\n",
    "params = {'C': [0.01, 0.1, 1.0, 10.0, 30.0, 100.0],\n",
    "          'gamma': ['auto', 0.1, 1.0, 10.0],\n",
    "          'kernel': ['linear', 'rbf']}\n",
    "gssvm = GridSearchCV(svm, params,\n",
    "                   n_jobs=-1, cv=KFold(len(y), n_folds=5, shuffle=True))\n",
    "gssvm.fit(X,y)\n",
    "print gssvm.best_params_\n",
    "print gssvm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Our GridSearch did even better with our Support vector machine. Having our highest score of 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest & Extra Trees\n",
    "\n",
    "Let's see if Random Forest and Extra Trees perform better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.86319845857%\n",
      "8.67052023121%\n"
     ]
    }
   ],
   "source": [
    "# Lets try both of these models\n",
    "rf = RandomForestClassifier()\n",
    "evaluate_model(rf)\n",
    "#This model Performed poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 2, 'n_estimators': 50, 'criterion': 'entropy', 'max_depth': 3, 'class_weight': None}\n",
      "0.310185185185\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch parameters \n",
    "params = {'n_estimators':[3, 5, 10, 50],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 3, 5],\n",
    "          'min_samples_split': [2,5],\n",
    "          'class_weight':[None, 'balanced']}\n",
    "\n",
    "\n",
    "gsrf = GridSearchCV(RandomForestClassifier(n_jobs=-1),\n",
    "                    params, n_jobs=-1,\n",
    "                    cv=KFold(len(y), n_folds=5, shuffle=True))\n",
    "\n",
    "gsrf.fit(X,y)\n",
    "\n",
    "print gsrf.best_params_\n",
    "print gsrf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This was great practice seeing how models can be tuned using bagging classfiers along with grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
